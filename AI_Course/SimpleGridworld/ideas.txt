# TITLE
  Tuning Hyperparameter combination for Q-Learning

# Abstract
  Энэхүү өгүүлэлд бид Q-Leaning -ийн хамгийн бага хугацаанд үр дүнтэй сургах
  параметруудын утгууд болон хэрэглэж болох арга техникүүдийн хамаарлыг харуулсан болно.
  Сургалтын үр дүнгүүдээс learning rate нь суралцах хурд болон агентийн гаргах шийдвэрт
  экспонциал маягийн хамааралтайгаар хүчтэй нөлөө үзүүлж байгааг харж болно. 
  Тухайн суралцах орчин нөхцлөөс хамааран ашиглах арга техникийг зөв сонгох нь маш чухал
  учир эхлээд суралцах орчиноо үнэлснээр дараагийн удаа өмнөх орчиноос хамааруулан
  параметруудаа сонгох боломжтой болно.

# Keyword
  Reinforcement Learning, Q-Learning, Learning Rate, Discount Rate, Reward, Agent, State, Action
  Environment, Q-Table, 

# Introduction
  Reinforcement Learning нь машин сургалтын үндсэн 3 аргуудын нэг юм. RL -ийн агент нь өөрийн хүрээлэн буй
  орчинд тодорхой нэг үйлдэл(action) хийх ба үр дүнд агентын нөхцөл байдлаас хамааран тодорхой хэмжээний
  шагнал(reward) авна. Reward ямар байхаас хамааран тухайн нөхцөл байдалд ямар үйлдэл хйигээд ямар нөхцөл
  байдалд орсоноос хамааран дүгнэх замаар агентыг сургадаг. Бидний ашигласан Q-Leaning арга нь Q-Table
  бүхий хүснэгт үүсгэн үр дүнг хадгалдаг ба сургалтын явцад энэхүү Q-Table -аа сайжруулж байдаг.
  Харин хэрхэн сайжруулах вэ гэдэг бидний хйих ёстой зүйл юм. 

# STEP REWARD AND EPSILON DIFFERENCE

  Хэрэв рандомчлалын коэффицет байхгүй бол агент 
  Q-table-аа дагаж хоёр чиглэлд явна. Рандомчлалын коеффицент
  байвал агент шинэ үйлдэл хийж бусад state үүдийг судлах боломжтой болно.
  Гэвч агентыг зөв үйлдэл хийж байгаа эсвэл буруу үйлдэл хийж байгаа эсэхэд
  дүгнэлт гаргах боломжгүй болно. Өөрөөр хэлвэл агентын хийж буй үйлдэл
  санамсаргүй учир сайн ч байж болно муу ч байж болно. Харин суралцах явцад
  санамсаргүй үйлдэл байснаар зөв policy үүссэн ч policy-гоос хамаар ч явахгүй
  байж болох юм. Энэ тохиолдолд рандомчлалын коэффицетийг суралцах явцад бага 
  багаар багасгах замаар рандомчлалын коэффицетыг үгүй болгож болно. Ингэснээр
  тодорхой хугацааны дараа агент зөвхөн policy-гоос хамааралтай болно.
  Гэвч энэ арга нь сургалтын хугацааны хувьд удах хандлагатай байдгийг 
  туршлагаар харсан.

  Хэрэв 

	КОМБИНАЦ
  
  
  
  

  Иймээс майна тоглоомын орчинд 